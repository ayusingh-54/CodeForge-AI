# Frontend — CodeForge AI

This folder contains a small, self-contained frontend for the CodeForge AI project.
It is intended to be easy to run locally (demo mode) and to be straightforward to wire
to a backend that proxies requests to the OpenAI API.

## Files

- `index.html` — The single-page markup. Contains the landing content and the
  interactive chat panel. Read the inline comments for details.
- `styles.css` — The styling for the layout, chat panel, theme toggles and responsive behavior.
- `script.js` — The client-side logic: demo-mode responses, backend hooks, persistence, and utilities.

## Quick start

1. Open `Frontend/index.html` in your browser. This runs in demo mode by default.
2. Type a message into the chat composer and press Enter to send (Shift+Enter for newline).
3. Use the dropdown near the chat header to switch between `Demo Mode` and `Use Backend`.
4. Use Export to save the conversation as JSON, or Clear to reset the chat.

## Demo mode vs Backend mode

- Demo mode: All behavior runs locally in your browser. No API calls or keys required. Responses
  are generated by a small deterministic helper in `script.js` (`demoGenerateReply`) and are meant
  to illustrate UX and message flows.
- Backend mode: The frontend will POST JSON to `/api/ai`. The expected request and response formats
  are described below. You must implement a server-side endpoint that calls OpenAI (or another model)
  and returns only the text reply. Keep your API keys secret on the server.

## Recommended server API contract

Request (POST /api/ai)

Content-Type: application/json

Body: { "message": "User's text message here" }

Response (200 OK)

Content-Type: application/json

Body: { "reply": "Assistant reply text" }

## Minimal example (Python + Flask)

This is a tiny example that shows the server receiving a message and responding.
Implement the actual OpenAI call securely on the server (do not put secrets in frontend).

```python
from flask import Flask, request, jsonify
import os
import openai

app = Flask(__name__)
openai.api_key = os.environ.get('OPENAI_API_KEY')

@app.route('/api/ai', methods=['POST'])
def ai():
    data = request.json or {}
    message = data.get('message', '')
    if not message:
        return jsonify({'reply': 'No message provided.'}), 400

    # Example using OpenAI (pseudocode)
    resp = openai.ChatCompletion.create(
        model='gpt-4o-mini',
        messages=[{'role':'user', 'content': message}],
        max_tokens=512
    )
    # Extract text safely: APIs differ; adjust to your SDK
    reply = resp.choices[0].message.content if getattr(resp, 'choices', None) else str(resp)
    return jsonify({'reply': reply})

if __name__ == '__main__':
    app.run(port=8000, debug=True)
```

## Minimal example (Node.js + Express)

```js
const express = require("express");
const bodyParser = require("body-parser");
const OpenAI = require("openai");

const app = express();
app.use(bodyParser.json());

const client = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

app.post("/api/ai", async (req, res) => {
  const message = req.body?.message || "";
  if (!message) return res.status(400).json({ reply: "No message provided." });

  const completion = await client.chat.completions.create({
    model: "gpt-4o-mini",
    messages: [{ role: "user", content: message }],
  });
  const reply = completion.choices?.[0]?.message?.content || "No reply";
  res.json({ reply });
});

app.listen(8000, () =>
  console.log("Server listening on http://localhost:8000")
);
```

## Security notes

- Never expose your API key in the frontend or check it into source control.
- Validate and sanitize inputs on the server; apply rate limits and auth as needed.
- Keep CORS strict if exposing the endpoint publicly — allow only trusted origins.

## Customization & tips

- To change demo replies, edit `script.js` -> `demoGenerateReply()`.
- To change the appearance, edit `styles.css`. The file supports a light theme via
  the `data-theme="light"` attribute on the document root (a toggle is provided in the UI).
- To change the export format, modify the export button handler in `script.js`.

## Troubleshooting

- If the backend returns 500, check your server logs and ensure the OpenAI client is configured
  correctly on the server side.
- If messages do not persist, verify browser localStorage privacy settings or use a different key.

## README summary

This folder is a minimal, well-documented frontend to prototype an AI assistant experience.
Use demo mode for offline UX demos. Wire to a backend following the contract above for real AI replies.

If you'd like, I can:

- Add a ready-made small Flask or Express server in the repo to demonstrate full end-to-end calls.
- Add unit tests for the frontend utilities.

Enjoy — and be careful with API keys!
